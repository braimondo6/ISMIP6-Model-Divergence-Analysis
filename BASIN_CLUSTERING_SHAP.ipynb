{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68197361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 unique basins: [1 2 3 4 5 6 7]\n",
      "Loaded model characteristics from C:\\Users\\benra\\ISMIP6_EXP_ALL - GIS_Model_Characteristics.csv. Shape: (21, 12)\n",
      "\n",
      "--- Processing Basin: SW (ID: 1) for SHAP Analysis ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benra\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\benra\\AppData\\Local\\Temp\\ipykernel_5692\\171517378.py:239: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cluster_colors = [plt.cm.get_cmap('Set1')(i) for i in range(n_clusters_kmeans)]\n",
      "C:\\Users\\benra\\AppData\\Local\\Temp\\ipykernel_5692\\171517378.py:292: RuntimeWarning: invalid value encountered in sqrt\n",
      "  height = 2 * np.sqrt(eigenvalues[1] * chi2_val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Creating PCA scatter plot for Basin SW\n",
      "  PCA scatter plot saved: PCA_2D_Scatter_Exp_expa03_Basin_SW.png\n",
      "  Shape of X_shap_cleaned (features for SHAP): (15, 21)\n",
      "  Cluster distribution: [2 4 5 3 1]\n",
      "  Clusters present in Basin SW: [0 1 2 3 4]\n",
      "    Processing Cluster 0 (2 models)\n",
      "      Cluster 0: 2 positive, 13 negative samples\n",
      "      Binary classifier accuracy for Cluster 0: 1.00\n",
      "      Prediction probability range: 0.865\n",
      "      SHAP value range: 2.6232, Mean absolute SHAP: 0.1249\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_0_Exp_expa03_Basin_SW.png\n",
      "    Processing Cluster 1 (4 models)\n",
      "      Cluster 1: 4 positive, 11 negative samples\n",
      "      Binary classifier accuracy for Cluster 1: 0.87\n",
      "      Prediction probability range: 0.790\n",
      "      SHAP value range: 2.3239, Mean absolute SHAP: 0.1528\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_1_Exp_expa03_Basin_SW.png\n",
      "    Processing Cluster 2 (5 models)\n",
      "      Cluster 2: 5 positive, 10 negative samples\n",
      "      Binary classifier accuracy for Cluster 2: 1.00\n",
      "      Prediction probability range: 0.812\n",
      "      SHAP value range: 1.1504, Mean absolute SHAP: 0.2088\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_2_Exp_expa03_Basin_SW.png\n",
      "    Processing Cluster 3 (3 models)\n",
      "      Cluster 3: 3 positive, 12 negative samples\n",
      "      Binary classifier accuracy for Cluster 3: 1.00\n",
      "      Prediction probability range: 0.800\n",
      "      SHAP value range: 1.3074, Mean absolute SHAP: 0.1192\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_3_Exp_expa03_Basin_SW.png\n",
      "    Processing Cluster 4 (1 models)\n",
      "      Cluster 4: 1 positive, 14 negative samples\n",
      "      Insufficient samples for meaningful classification. Skipping Cluster 4.\n",
      "\n",
      "--- SHAP Analysis Complete for Basin SW ---\n",
      "Created SHAP summary plots for all 5 clusters\n",
      "\n",
      "--- All Basin SHAP Analysis Complete ---\n",
      "\n",
      "--- Processing Basin: SE (ID: 2) for SHAP Analysis ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benra\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\benra\\AppData\\Local\\Temp\\ipykernel_5692\\171517378.py:239: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cluster_colors = [plt.cm.get_cmap('Set1')(i) for i in range(n_clusters_kmeans)]\n",
      "C:\\Users\\benra\\AppData\\Local\\Temp\\ipykernel_5692\\171517378.py:292: RuntimeWarning: invalid value encountered in sqrt\n",
      "  height = 2 * np.sqrt(eigenvalues[1] * chi2_val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Creating PCA scatter plot for Basin SE\n",
      "  PCA scatter plot saved: PCA_2D_Scatter_Exp_expa03_Basin_SE.png\n",
      "  Shape of X_shap_cleaned (features for SHAP): (15, 21)\n",
      "  Cluster distribution: [2 5 4 3 1]\n",
      "  Clusters present in Basin SE: [0 1 2 3 4]\n",
      "    Processing Cluster 0 (2 models)\n",
      "      Cluster 0: 2 positive, 13 negative samples\n",
      "      Binary classifier accuracy for Cluster 0: 1.00\n",
      "      Prediction probability range: 0.865\n",
      "      SHAP value range: 2.6232, Mean absolute SHAP: 0.1249\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_0_Exp_expa03_Basin_SE.png\n",
      "    Processing Cluster 1 (5 models)\n",
      "      Cluster 1: 5 positive, 10 negative samples\n",
      "      Binary classifier accuracy for Cluster 1: 1.00\n",
      "      Prediction probability range: 0.760\n",
      "      SHAP value range: 2.4044, Mean absolute SHAP: 0.1106\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_1_Exp_expa03_Basin_SE.png\n",
      "    Processing Cluster 2 (4 models)\n",
      "      Cluster 2: 4 positive, 11 negative samples\n",
      "      Binary classifier accuracy for Cluster 2: 0.93\n",
      "      Prediction probability range: 0.897\n",
      "      SHAP value range: 2.5152, Mean absolute SHAP: 0.2314\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_2_Exp_expa03_Basin_SE.png\n",
      "    Processing Cluster 3 (3 models)\n",
      "      Cluster 3: 3 positive, 12 negative samples\n",
      "      Binary classifier accuracy for Cluster 3: 1.00\n",
      "      Prediction probability range: 0.800\n",
      "      SHAP value range: 1.3074, Mean absolute SHAP: 0.1192\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_3_Exp_expa03_Basin_SE.png\n",
      "    Processing Cluster 4 (1 models)\n",
      "      Cluster 4: 1 positive, 14 negative samples\n",
      "      Insufficient samples for meaningful classification. Skipping Cluster 4.\n",
      "\n",
      "--- SHAP Analysis Complete for Basin SE ---\n",
      "Created SHAP summary plots for all 5 clusters\n",
      "\n",
      "--- All Basin SHAP Analysis Complete ---\n",
      "\n",
      "--- Processing Basin: CE (ID: 3) for SHAP Analysis ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benra\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\benra\\AppData\\Local\\Temp\\ipykernel_5692\\171517378.py:239: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cluster_colors = [plt.cm.get_cmap('Set1')(i) for i in range(n_clusters_kmeans)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Creating PCA scatter plot for Basin CE\n",
      "  PCA scatter plot saved: PCA_2D_Scatter_Exp_expa03_Basin_CE.png\n",
      "  Shape of X_shap_cleaned (features for SHAP): (15, 21)\n",
      "  Cluster distribution: [2 6 4 2 1]\n",
      "  Clusters present in Basin CE: [0 1 2 3 4]\n",
      "    Processing Cluster 0 (2 models)\n",
      "      Cluster 0: 2 positive, 13 negative samples\n",
      "      Binary classifier accuracy for Cluster 0: 1.00\n",
      "      Prediction probability range: 0.865\n",
      "      SHAP value range: 2.6232, Mean absolute SHAP: 0.1249\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_0_Exp_expa03_Basin_CE.png\n",
      "    Processing Cluster 1 (6 models)\n",
      "      Cluster 1: 6 positive, 9 negative samples\n",
      "      Binary classifier accuracy for Cluster 1: 0.87\n",
      "      Prediction probability range: 0.866\n",
      "      SHAP value range: 1.6722, Mean absolute SHAP: 0.1341\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_1_Exp_expa03_Basin_CE.png\n",
      "    Processing Cluster 2 (4 models)\n",
      "      Cluster 2: 4 positive, 11 negative samples\n",
      "      Binary classifier accuracy for Cluster 2: 1.00\n",
      "      Prediction probability range: 0.888\n",
      "      SHAP value range: 1.6888, Mean absolute SHAP: 0.1413\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_2_Exp_expa03_Basin_CE.png\n",
      "    Processing Cluster 3 (2 models)\n",
      "      Cluster 3: 2 positive, 13 negative samples\n",
      "      Binary classifier accuracy for Cluster 3: 1.00\n",
      "      Prediction probability range: 0.847\n",
      "      SHAP value range: 1.8915, Mean absolute SHAP: 0.1851\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_3_Exp_expa03_Basin_CE.png\n",
      "    Processing Cluster 4 (1 models)\n",
      "      Cluster 4: 1 positive, 14 negative samples\n",
      "      Insufficient samples for meaningful classification. Skipping Cluster 4.\n",
      "\n",
      "--- SHAP Analysis Complete for Basin CE ---\n",
      "Created SHAP summary plots for all 5 clusters\n",
      "\n",
      "--- All Basin SHAP Analysis Complete ---\n",
      "\n",
      "--- Processing Basin: NE (ID: 4) for SHAP Analysis ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benra\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\benra\\AppData\\Local\\Temp\\ipykernel_5692\\171517378.py:239: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cluster_colors = [plt.cm.get_cmap('Set1')(i) for i in range(n_clusters_kmeans)]\n",
      "C:\\Users\\benra\\AppData\\Local\\Temp\\ipykernel_5692\\171517378.py:292: RuntimeWarning: invalid value encountered in sqrt\n",
      "  height = 2 * np.sqrt(eigenvalues[1] * chi2_val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Creating PCA scatter plot for Basin NE\n",
      "  PCA scatter plot saved: PCA_2D_Scatter_Exp_expa03_Basin_NE.png\n",
      "  Shape of X_shap_cleaned (features for SHAP): (15, 21)\n",
      "  Cluster distribution: [2 7 4 1 1]\n",
      "  Clusters present in Basin NE: [0 1 2 3 4]\n",
      "    Processing Cluster 0 (2 models)\n",
      "      Cluster 0: 2 positive, 13 negative samples\n",
      "      Binary classifier accuracy for Cluster 0: 1.00\n",
      "      Prediction probability range: 0.865\n",
      "      SHAP value range: 2.6232, Mean absolute SHAP: 0.1249\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_0_Exp_expa03_Basin_NE.png\n",
      "    Processing Cluster 1 (7 models)\n",
      "      Cluster 1: 7 positive, 8 negative samples\n",
      "      Binary classifier accuracy for Cluster 1: 0.87\n",
      "      Prediction probability range: 0.794\n",
      "      SHAP value range: 1.7215, Mean absolute SHAP: 0.1049\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_1_Exp_expa03_Basin_NE.png\n",
      "    Processing Cluster 2 (4 models)\n",
      "      Cluster 2: 4 positive, 11 negative samples\n",
      "      Binary classifier accuracy for Cluster 2: 1.00\n",
      "      Prediction probability range: 0.888\n",
      "      SHAP value range: 1.6888, Mean absolute SHAP: 0.1413\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_2_Exp_expa03_Basin_NE.png\n",
      "    Processing Cluster 3 (1 models)\n",
      "      Cluster 3: 1 positive, 14 negative samples\n",
      "      Insufficient samples for meaningful classification. Skipping Cluster 3.\n",
      "    Processing Cluster 4 (1 models)\n",
      "      Cluster 4: 1 positive, 14 negative samples\n",
      "      Insufficient samples for meaningful classification. Skipping Cluster 4.\n",
      "\n",
      "--- SHAP Analysis Complete for Basin NE ---\n",
      "Created SHAP summary plots for all 5 clusters\n",
      "\n",
      "--- All Basin SHAP Analysis Complete ---\n",
      "\n",
      "--- Processing Basin: NO (ID: 5) for SHAP Analysis ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benra\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\benra\\AppData\\Local\\Temp\\ipykernel_5692\\171517378.py:239: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cluster_colors = [plt.cm.get_cmap('Set1')(i) for i in range(n_clusters_kmeans)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Creating PCA scatter plot for Basin NO\n",
      "  PCA scatter plot saved: PCA_2D_Scatter_Exp_expa03_Basin_NO.png\n",
      "  Shape of X_shap_cleaned (features for SHAP): (15, 21)\n",
      "  Cluster distribution: [2 4 5 1 3]\n",
      "  Clusters present in Basin NO: [0 1 2 3 4]\n",
      "    Processing Cluster 0 (2 models)\n",
      "      Cluster 0: 2 positive, 13 negative samples\n",
      "      Binary classifier accuracy for Cluster 0: 1.00\n",
      "      Prediction probability range: 0.865\n",
      "      SHAP value range: 2.6232, Mean absolute SHAP: 0.1249\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_0_Exp_expa03_Basin_NO.png\n",
      "    Processing Cluster 1 (4 models)\n",
      "      Cluster 1: 4 positive, 11 negative samples\n",
      "      Binary classifier accuracy for Cluster 1: 0.93\n",
      "      Prediction probability range: 0.874\n",
      "      SHAP value range: 2.1046, Mean absolute SHAP: 0.1253\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_1_Exp_expa03_Basin_NO.png\n",
      "    Processing Cluster 2 (5 models)\n",
      "      Cluster 2: 5 positive, 10 negative samples\n",
      "      Binary classifier accuracy for Cluster 2: 1.00\n",
      "      Prediction probability range: 0.879\n",
      "      SHAP value range: 0.9136, Mean absolute SHAP: 0.1569\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_2_Exp_expa03_Basin_NO.png\n",
      "    Processing Cluster 3 (1 models)\n",
      "      Cluster 3: 1 positive, 14 negative samples\n",
      "      Insufficient samples for meaningful classification. Skipping Cluster 3.\n",
      "    Processing Cluster 4 (3 models)\n",
      "      Cluster 4: 3 positive, 12 negative samples\n",
      "      Binary classifier accuracy for Cluster 4: 1.00\n",
      "      Prediction probability range: 0.924\n",
      "      SHAP value range: 2.3804, Mean absolute SHAP: 0.1603\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_4_Exp_expa03_Basin_NO.png\n",
      "\n",
      "--- SHAP Analysis Complete for Basin NO ---\n",
      "Created SHAP summary plots for all 5 clusters\n",
      "\n",
      "--- All Basin SHAP Analysis Complete ---\n",
      "\n",
      "--- Processing Basin: NW (ID: 6) for SHAP Analysis ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benra\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\benra\\AppData\\Local\\Temp\\ipykernel_5692\\171517378.py:239: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cluster_colors = [plt.cm.get_cmap('Set1')(i) for i in range(n_clusters_kmeans)]\n",
      "C:\\Users\\benra\\AppData\\Local\\Temp\\ipykernel_5692\\171517378.py:292: RuntimeWarning: invalid value encountered in sqrt\n",
      "  height = 2 * np.sqrt(eigenvalues[1] * chi2_val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Creating PCA scatter plot for Basin NW\n",
      "  PCA scatter plot saved: PCA_2D_Scatter_Exp_expa03_Basin_NW.png\n",
      "  Shape of X_shap_cleaned (features for SHAP): (15, 21)\n",
      "  Cluster distribution: [2 7 2 3 1]\n",
      "  Clusters present in Basin NW: [0 1 2 3 4]\n",
      "    Processing Cluster 0 (2 models)\n",
      "      Cluster 0: 2 positive, 13 negative samples\n",
      "      Binary classifier accuracy for Cluster 0: 1.00\n",
      "      Prediction probability range: 0.865\n",
      "      SHAP value range: 2.6232, Mean absolute SHAP: 0.1249\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_0_Exp_expa03_Basin_NW.png\n",
      "    Processing Cluster 1 (7 models)\n",
      "      Cluster 1: 7 positive, 8 negative samples\n",
      "      Binary classifier accuracy for Cluster 1: 0.93\n",
      "      Prediction probability range: 0.773\n",
      "      SHAP value range: 1.9363, Mean absolute SHAP: 0.1046\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_1_Exp_expa03_Basin_NW.png\n",
      "    Processing Cluster 2 (2 models)\n",
      "      Cluster 2: 2 positive, 13 negative samples\n",
      "      Binary classifier accuracy for Cluster 2: 1.00\n",
      "      Prediction probability range: 0.865\n",
      "      SHAP value range: 2.6232, Mean absolute SHAP: 0.1249\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_2_Exp_expa03_Basin_NW.png\n",
      "    Processing Cluster 3 (3 models)\n",
      "      Cluster 3: 3 positive, 12 negative samples\n",
      "      Binary classifier accuracy for Cluster 3: 1.00\n",
      "      Prediction probability range: 0.800\n",
      "      SHAP value range: 1.3074, Mean absolute SHAP: 0.1192\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_3_Exp_expa03_Basin_NW.png\n",
      "    Processing Cluster 4 (1 models)\n",
      "      Cluster 4: 1 positive, 14 negative samples\n",
      "      Insufficient samples for meaningful classification. Skipping Cluster 4.\n",
      "\n",
      "--- SHAP Analysis Complete for Basin NW ---\n",
      "Created SHAP summary plots for all 5 clusters\n",
      "\n",
      "--- All Basin SHAP Analysis Complete ---\n",
      "\n",
      "--- Processing Basin: CW (ID: 7) for SHAP Analysis ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benra\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\benra\\AppData\\Local\\Temp\\ipykernel_5692\\171517378.py:239: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cluster_colors = [plt.cm.get_cmap('Set1')(i) for i in range(n_clusters_kmeans)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Creating PCA scatter plot for Basin CW\n",
      "  PCA scatter plot saved: PCA_2D_Scatter_Exp_expa03_Basin_CW.png\n",
      "  Shape of X_shap_cleaned (features for SHAP): (15, 21)\n",
      "  Cluster distribution: [2 6 4 2 1]\n",
      "  Clusters present in Basin CW: [0 1 2 3 4]\n",
      "    Processing Cluster 0 (2 models)\n",
      "      Cluster 0: 2 positive, 13 negative samples\n",
      "      Binary classifier accuracy for Cluster 0: 1.00\n",
      "      Prediction probability range: 0.865\n",
      "      SHAP value range: 2.6232, Mean absolute SHAP: 0.1249\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_0_Exp_expa03_Basin_CW.png\n",
      "    Processing Cluster 1 (6 models)\n",
      "      Cluster 1: 6 positive, 9 negative samples\n",
      "      Binary classifier accuracy for Cluster 1: 0.93\n",
      "      Prediction probability range: 0.757\n",
      "      SHAP value range: 2.2423, Mean absolute SHAP: 0.0954\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_1_Exp_expa03_Basin_CW.png\n",
      "    Processing Cluster 2 (4 models)\n",
      "      Cluster 2: 4 positive, 11 negative samples\n",
      "      Binary classifier accuracy for Cluster 2: 1.00\n",
      "      Prediction probability range: 0.888\n",
      "      SHAP value range: 1.6888, Mean absolute SHAP: 0.1413\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_2_Exp_expa03_Basin_CW.png\n",
      "    Processing Cluster 3 (2 models)\n",
      "      Cluster 3: 2 positive, 13 negative samples\n",
      "      Binary classifier accuracy for Cluster 3: 1.00\n",
      "      Prediction probability range: 0.887\n",
      "      SHAP value range: 1.8437, Mean absolute SHAP: 0.2181\n",
      "      SHAP Summary Plot saved: SHAP_Summary_Cluster_3_Exp_expa03_Basin_CW.png\n",
      "    Processing Cluster 4 (1 models)\n",
      "      Cluster 4: 1 positive, 14 negative samples\n",
      "      Insufficient samples for meaningful classification. Skipping Cluster 4.\n",
      "\n",
      "--- SHAP Analysis Complete for Basin CW ---\n",
      "Created SHAP summary plots for all 5 clusters\n",
      "\n",
      "--- All Basin SHAP Analysis Complete ---\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import os\n",
    "import re\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage.transform import resize\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cm\n",
    "import itertools \n",
    "from matplotlib.patches import Ellipse\n",
    "from scipy import stats \n",
    "\n",
    "# --- Configuration ---\n",
    "# Base directory where your experiment folders are located\n",
    "base_data_dir = r\"C:\\Users\\benra\"\n",
    "\n",
    "# Path to your basin mask NetCDF file\n",
    "basin_mask_path = r\"C:\\Users\\benra\\output_combined_masked_basins.nc\"\n",
    "\n",
    "# Path to your model characteristics CSV file\n",
    "model_characteristics_path = r\"C:\\Users\\benra\\ISMIP6_EXP_ALL - GIS_Model_Characteristics.csv\"\n",
    "\n",
    "# The specific experiment ID for which you want to calculate SHAP values across all basins\n",
    "shap_experiment_id = 'expa03' \n",
    "\n",
    "# Variable name for ice thickness in your NetCDF files\n",
    "variable_name = 'lithk'\n",
    "\n",
    "# PCA and K-means parameters for outlier score calculation\n",
    "n_components_pca = 4  # Number of PCA components to retain for clustering and outlier scoring\n",
    "n_clusters_kmeans = 5 # Number of clusters for K-means\n",
    "\n",
    "# Time window for delta calculation (using full time series for SHAP)\n",
    "time_window_start_idx = 0   # Index for 2015\n",
    "time_window_end_idx = 85    # Index for 2100\n",
    "time_window_label = '2015-2100' # Label for plots and output folders\n",
    "\n",
    "# Output directory for SHAP plots\n",
    "output_plots_dir = \"Research_Plots\"\n",
    "shap_output_dir = os.path.join(output_plots_dir, \"SHAP_Plots_Per_Basin_Cluster\")\n",
    "os.makedirs(shap_output_dir, exist_ok=True)\n",
    "exp_output_dir = os.path.join(shap_output_dir, f\"{shap_experiment_id}\")\n",
    "os.makedirs(exp_output_dir, exist_ok=True)\n",
    "pca_plot_output_dir = os.path.join(exp_output_dir, \"PCA_KMeans_Plots\")\n",
    "os.makedirs(pca_plot_output_dir, exist_ok=True)\n",
    "\n",
    "# --- Define Features for One-Hot Encoding ---\n",
    "# This list specifies which columns from your model_characteristics_df\n",
    "# should be treated as categorical features and one-hot encoded for SHAP analysis.\n",
    "CATEGORICAL_FEATURES_TO_ENCODE = [\n",
    "    'Initialisation',\n",
    "    'Numerics',\n",
    "    'Ice flow',\n",
    "    'Initial SMB',\n",
    "    'Bed',\n",
    "    'GH F'\n",
    "]\n",
    "\n",
    "# --- Basin Geographic Names Mapping ---\n",
    "basin_names = {\n",
    "    1: 'SW',\n",
    "    2: 'SE',\n",
    "    3: 'CE',\n",
    "    4: 'NE',\n",
    "    5: 'NO',\n",
    "    6: 'NW',\n",
    "    7: 'CW'\n",
    "}\n",
    "\n",
    "# --- Define the standardization function for model names ---\n",
    "def standardize_model_name(model_name_from_netcdf):\n",
    "    \"\"\"\n",
    "    Transforms a model name from the NetCDF derived format\n",
    "    to match the 'Model ID' format in the characteristics CSV.\n",
    "    \"\"\"\n",
    "    # Specific rules for ILTS_PIK_SICOPOLIS models (example from your notebook)\n",
    "    if model_name_from_netcdf == 'ILTS_PIK_SICOPOLIS1':\n",
    "        return 'ILTSPIK- SICOPOLIS1'\n",
    "    elif model_name_from_netcdf == 'ILTS_PIK_SICOPOLIS2':\n",
    "        return 'ILTSPIK- SICOPOLIS2'\n",
    "    \n",
    "    # General rule: for all other models, replace underscores with dashes\n",
    "    return model_name_from_netcdf.replace('_', '-')\n",
    "\n",
    "# --- Load Basin Mask ---\n",
    "try:\n",
    "    basin_mask_data = xr.open_dataset(basin_mask_path)\n",
    "    basin_id_var_name = None\n",
    "    for var_key in basin_mask_data.data_vars.keys():\n",
    "        if var_key.strip() == 'IDs':\n",
    "            basin_id_var_name = var_key\n",
    "            break\n",
    "    \n",
    "    if basin_id_var_name is None:\n",
    "        raise KeyError(\"Could not find 'IDs' variable (even after stripping whitespace) in basin mask NetCDF.\")\n",
    "\n",
    "    basin_ids_grid = basin_mask_data[basin_id_var_name]\n",
    "    unique_basin_ids = np.unique(basin_ids_grid.values[~np.isnan(basin_ids_grid.values)]).astype(int)\n",
    "    print(f\"Found {len(unique_basin_ids)} unique basins: {unique_basin_ids}\")\n",
    "\n",
    "    # Get grid coordinates and shape from the basin mask\n",
    "    x_coords_grid = basin_ids_grid['x'].values if 'x' in basin_ids_grid.coords else basin_ids_grid.coords[basin_ids_grid.dims[1]].values\n",
    "    y_coords_grid = basin_ids_grid['y'].values if 'y' in basin_ids_grid.coords else basin_ids_grid.coords[basin_ids_grid.dims[0]].values\n",
    "    rows_grid, cols_grid = basin_ids_grid.shape\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Basin mask file not found at {basin_mask_path}\")\n",
    "    exit()\n",
    "except KeyError as e:\n",
    "    print(f\"Error: {e}. Please check the variable name or file path for the basin mask.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while loading basin mask: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Load Model Characteristics CSV ---\n",
    "try:\n",
    "    model_characteristics_df = pd.read_csv(model_characteristics_path)\n",
    "    # Ensure 'Model ID' column exists and is suitable for merging\n",
    "    if 'Model ID' not in model_characteristics_df.columns:\n",
    "        raise ValueError(f\"'{model_characteristics_path}' must contain a 'Model ID' column.\")\n",
    "    print(f\"Loaded model characteristics from {model_characteristics_path}. Shape: {model_characteristics_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Model characteristics CSV file not found at {model_characteristics_path}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while loading model characteristics: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Main Analysis Loop: Per Basin ---\n",
    "all_shap_results = [] # To store SHAP values for all basins if needed later\n",
    "\n",
    "for basin_id in unique_basin_ids:\n",
    "    basin_geo_name = basin_names.get(basin_id, f\"Basin {basin_id}\")\n",
    "    print(f\"\\n--- Processing Basin: {basin_geo_name} (ID: {basin_id}) for SHAP Analysis ---\")\n",
    "\n",
    "    # Construct the actual folder name for the current experiment\n",
    "    experiment_folder_name = f\"{variable_name}_{shap_experiment_id}\"\n",
    "    netcdf_dir = os.path.join(base_data_dir, experiment_folder_name)\n",
    "\n",
    "    if not os.path.exists(netcdf_dir):\n",
    "        print(f\"  Warning: Experiment directory not found for {shap_experiment_id} at {netcdf_dir}. Skipping this basin.\")\n",
    "        continue\n",
    "\n",
    "    netcdf_files = [os.path.join(netcdf_dir, f) for f in os.listdir(netcdf_dir) if f.endswith('.nc')]\n",
    "\n",
    "    current_basin_deltas = []\n",
    "    current_basin_models_present = []\n",
    "\n",
    "    # Loop through each model in the selected experiment's directory\n",
    "    for i, file_path in enumerate(netcdf_files):\n",
    "        base_filename = os.path.basename(file_path)\n",
    "        \n",
    "        # Extract raw model name and standardize\n",
    "        model_id_raw = base_filename.replace('.nc', '')\n",
    "        model_id_raw = model_id_raw.replace(f'{variable_name}_GIS_', '')\n",
    "        if model_id_raw.endswith(f'_{shap_experiment_id}'):\n",
    "            model_id_raw = model_id_raw.replace(f'_{shap_experiment_id}', '')\n",
    "        model_id_raw = re.sub(r'_\\d+$', '', model_id_raw) # Remove _<digits> if present\n",
    "        standardized_model_id = standardize_model_name(model_id_raw)\n",
    "\n",
    "        try:\n",
    "            model_ds = xr.open_dataset(file_path, decode_times=False)\n",
    "            if 'time' not in model_ds[variable_name].dims or len(model_ds['time']) < time_window_end_idx + 1:\n",
    "                print(f\"    Warning: '{variable_name}' in {standardized_model_id}/{shap_experiment_id} has insufficient time dimension for {time_window_label}. Skipping.\")\n",
    "                model_ds.close()\n",
    "                continue\n",
    "\n",
    "            delta_lithk = model_ds[variable_name].isel(time=time_window_end_idx) - model_ds[variable_name].isel(time=time_window_start_idx)\n",
    "            model_ds.close()\n",
    "\n",
    "            # Align delta_lithk to basin_ids_grid (important for correct masking)\n",
    "            target_dims = basin_ids_grid.dims\n",
    "            if len(delta_lithk.dims) == len(target_dims):\n",
    "                dim_rename_map = {old_dim: new_dim for old_dim, new_dim in zip(delta_lithk.dims, target_dims)}\n",
    "                delta_lithk_aligned = delta_lithk.rename(dim_rename_map)\n",
    "            else:\n",
    "                print(f\"    Warning: Delta_lithk for {standardized_model_id} in {shap_experiment_id} has unexpected dimensions: {delta_lithk.dims}. Skipping alignment.\")\n",
    "                delta_lithk_aligned = delta_lithk\n",
    "\n",
    "            delta_lithk_reindexed = delta_lithk_aligned.reindex_like(basin_ids_grid, method='nearest', tolerance=1e-6)\n",
    "\n",
    "            basin_specific_delta = delta_lithk_reindexed.where(basin_ids_grid == basin_id)\n",
    "\n",
    "            # Flatten and append\n",
    "            flattened_delta = basin_specific_delta.values.flatten()\n",
    "            current_basin_deltas.append(flattened_delta)\n",
    "            current_basin_models_present.append(standardized_model_id)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"    Error processing {standardized_model_id} in {shap_experiment_id}: {e}. Skipping.\")\n",
    "            if 'model_ds' in locals() and model_ds is not None:\n",
    "                model_ds.close()\n",
    "            continue\n",
    "\n",
    "    if not current_basin_models_present:\n",
    "        print(f\"  No valid model data found for Experiment {shap_experiment_id} in Basin {basin_geo_name}. Skipping SHAP analysis for this basin.\")\n",
    "        continue\n",
    "\n",
    "    # Stack all models' basin-specific deltas into a matrix\n",
    "    all_models_basin_data = np.stack(current_basin_deltas)\n",
    "\n",
    "    # Handle NaNs: Remove grid points that are NaN for any model in this basin/experiment\n",
    "    mask_valid_points = ~np.any(np.isnan(all_models_basin_data), axis=0)\n",
    "    data_matrix_for_clustering = all_models_basin_data[:, mask_valid_points]\n",
    "\n",
    "    if data_matrix_for_clustering.shape[1] == 0:\n",
    "        print(f\"  No valid (non-NaN) data points for clustering in Experiment {shap_experiment_id}, Basin {basin_geo_name}. Skipping SHAP analysis.\")\n",
    "        continue\n",
    "    # --- Perform PCA ---\n",
    "    scaler = StandardScaler()\n",
    "    data_matrix_scaled = scaler.fit_transform(data_matrix_for_clustering)\n",
    "\n",
    "    pca = PCA(n_components=n_components_pca)\n",
    "    pca_scores = pca.fit_transform(data_matrix_scaled)\n",
    "\n",
    "    # --- Perform K-Means Clustering ---\n",
    "    kmeans = KMeans(n_clusters=n_clusters_kmeans, random_state=0, n_init='auto')\n",
    "    labels = kmeans.fit_predict(pca_scores)\n",
    "\n",
    "    # Calculate outlier scores based on distance to the 'main' cluster centroid\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    main_cluster_label = unique_labels[np.argmax(counts)]\n",
    "    main_cluster_centroid = kmeans.cluster_centers_[main_cluster_label]\n",
    "    outlier_scores = np.linalg.norm(pca_scores - main_cluster_centroid, axis=1)\n",
    "\n",
    "    # --- Create 2D PCA Scatter Plot ---\n",
    "    print(f\"  Creating PCA scatter plot for Basin {basin_geo_name}\")\n",
    "\n",
    "    # Improved Cluster Color Selection\n",
    "    if n_clusters_kmeans <= 9:\n",
    "        cluster_colors = [plt.cm.get_cmap('Set1')(i) for i in range(n_clusters_kmeans)]\n",
    "    elif n_clusters_kmeans <= 12:\n",
    "        cluster_colors = [plt.cm.get_cmap('Set3')(i) for i in range(n_clusters_kmeans)]\n",
    "    else:\n",
    "        cluster_colors = [plt.cm.get_cmap('hsv')(i/n_clusters_kmeans) for i in range(n_clusters_kmeans)]\n",
    "\n",
    "    # Define markers for different models\n",
    "    import itertools\n",
    "    markers = itertools.cycle(('o', '^', 's', 'D', 'v', 'P', 'X', '*', 'H', '<', '>'))\n",
    "    model_to_marker = {model: next(markers) for model in current_basin_models_present}\n",
    "\n",
    "    # Create 2D scatter plot\n",
    "    fig_2d, ax_2d = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "    # Plot each model with its cluster color and unique marker\n",
    "    for i, model_name in enumerate(current_basin_models_present):\n",
    "        cluster_id = labels[i]\n",
    "        color = cluster_colors[cluster_id]\n",
    "        marker = model_to_marker[model_name]\n",
    "\n",
    "        ax_2d.scatter(\n",
    "            pca_scores[i, 0],\n",
    "            pca_scores[i, 1],\n",
    "            c=[color],\n",
    "            marker=marker,\n",
    "            s=250,  # Large marker size\n",
    "            edgecolor='black',\n",
    "            alpha=0.8,\n",
    "            linewidth=1.5\n",
    "        )\n",
    "\n",
    "    # Add confidence ellipses for each cluster\n",
    "    from scipy import stats\n",
    "    from matplotlib.patches import Ellipse\n",
    "    confidence_level = 0.95\n",
    "    chi2_val = stats.chi2.ppf(confidence_level, df=2)\n",
    "\n",
    "    for cluster_id in np.unique(labels):\n",
    "        cluster_points = pca_scores[labels == cluster_id, :2]\n",
    "\n",
    "        if len(cluster_points) < 2:\n",
    "            continue\n",
    "\n",
    "        centroid = np.mean(cluster_points, axis=0)\n",
    "        covariance = np.cov(cluster_points, rowvar=False)\n",
    "\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(covariance)\n",
    "        order = eigenvalues.argsort()[::-1]\n",
    "        eigenvalues = eigenvalues[order]\n",
    "        eigenvectors = eigenvectors[:, order]\n",
    "\n",
    "        angle = np.degrees(np.arctan2(*eigenvectors[:, 0][::-1]))\n",
    "        width = 2 * np.sqrt(eigenvalues[0] * chi2_val)\n",
    "        height = 2 * np.sqrt(eigenvalues[1] * chi2_val)\n",
    "\n",
    "        ellipse_color = cluster_colors[cluster_id]\n",
    "        ellipse = Ellipse(xy=centroid, width=width, height=height,\n",
    "                         angle=angle, edgecolor=ellipse_color, fc='None',\n",
    "                         lw=2, alpha=0.7, zorder=0)\n",
    "        ax_2d.add_patch(ellipse)\n",
    "\n",
    "    # Create cluster legend\n",
    "    cluster_legend_handles = []\n",
    "    for i in range(n_clusters_kmeans):\n",
    "        cluster_legend_handles.append(plt.Line2D([0], [0], marker='o', color='w',\n",
    "                                               markerfacecolor=cluster_colors[i], markersize=10,\n",
    "                                               label=f'Cluster {i}', markeredgecolor='black'))\n",
    "\n",
    "    # Create model legend\n",
    "    model_legend_handles = []\n",
    "    for i, model_name in enumerate(current_basin_models_present):\n",
    "        cluster_id = labels[i]\n",
    "        model_color = cluster_colors[cluster_id]\n",
    "        model_legend_handles.append(plt.Line2D([0], [0], marker=model_to_marker[model_name], \n",
    "                                              color='w', markerfacecolor=model_color,\n",
    "                                              markersize=10, label=model_name, \n",
    "                                              markeredgecolor='black'))\n",
    "\n",
    "    # Add legends\n",
    "    first_legend = ax_2d.legend(handles=cluster_legend_handles, loc='upper left', \n",
    "                               title='Clusters', bbox_to_anchor=(1.05, 1))\n",
    "    ax_2d.add_artist(first_legend)\n",
    "    ax_2d.legend(handles=model_legend_handles, loc='lower left', \n",
    "                title='Models', bbox_to_anchor=(1.05, 0))\n",
    "\n",
    "    # Set labels and title\n",
    "    ax_2d.set_xlabel(f'Principal Component 1 ({pca.explained_variance_ratio_[0]*100:.1f}% explained variance)')\n",
    "    ax_2d.set_ylabel(f'Principal Component 2 ({pca.explained_variance_ratio_[1]*100:.1f}% explained variance)')\n",
    "    plt.title(f'PCA: PC1 vs PC2 - K-Means Clusters\\nExperiment: {shap_experiment_id}, Basin: {basin_geo_name}')\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "\n",
    "    # Save the scatter plot\n",
    "    scatter_filename = f'PCA_2D_Scatter_Exp_{shap_experiment_id}_Basin_{basin_geo_name}.png'\n",
    "    plt.savefig(os.path.join(pca_plot_output_dir, scatter_filename), bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"  PCA scatter plot saved: {scatter_filename}\")\n",
    "\n",
    "    # Create a DataFrame for this basin's results\n",
    "    basin_results_df = pd.DataFrame({\n",
    "        'model_name': current_basin_models_present,\n",
    "        'experiment_name': shap_experiment_id,\n",
    "        'basin_id': basin_id,\n",
    "        'basin_geo_name': basin_geo_name,\n",
    "        'time_window_label': time_window_label,\n",
    "        'cluster_label': labels,\n",
    "        'outlier_score': outlier_scores\n",
    "    })\n",
    "\n",
    "    # --- Merge with Model Characteristics ---\n",
    "    shap_input_df = pd.merge(basin_results_df, model_characteristics_df, \n",
    "                             left_on='model_name', right_on='Model ID', how='left')\n",
    "\n",
    "    # Drop columns that are not features for SHAP or are redundant\n",
    "    columns_to_drop = [\n",
    "        'model_name', 'experiment_name', 'basin_id', 'basin_geo_name',\n",
    "        'time_window_label', 'cluster_label', 'Model ID',\n",
    "        '#', 'exp_id', 'Unnamed: 5', 'Unnamed: 6', 'Velocity', 'Surface/ Thickness'\n",
    "    ]\n",
    "    columns_to_drop_existing = [col for col in columns_to_drop if col in shap_input_df.columns]\n",
    "    X_shap_raw = shap_input_df.drop(columns=columns_to_drop_existing + ['outlier_score'])\n",
    "\n",
    "    # Get cluster labels for SHAP analysis\n",
    "    y_clusters = shap_input_df['cluster_label']\n",
    "\n",
    "    # Handle NaNs in features\n",
    "    for col in X_shap_raw.columns:\n",
    "        if col in CATEGORICAL_FEATURES_TO_ENCODE:\n",
    "            X_shap_raw[col] = X_shap_raw[col].fillna('Missing').astype('category')\n",
    "        else:\n",
    "            X_shap_raw[col] = X_shap_raw[col].fillna(0) \n",
    "\n",
    "    # One-hot encode specified categorical features\n",
    "    X_shap_encoded = pd.get_dummies(X_shap_raw, columns=CATEGORICAL_FEATURES_TO_ENCODE, drop_first=True)\n",
    "\n",
    "    # Drop rows with any remaining NaNs\n",
    "    initial_samples = X_shap_encoded.shape[0]\n",
    "    X_shap_cleaned = X_shap_encoded.dropna()\n",
    "    y_clusters_cleaned = y_clusters[X_shap_cleaned.index]\n",
    "\n",
    "    if X_shap_cleaned.shape[0] == 0:\n",
    "        print(f\"  No valid samples for SHAP analysis after cleaning for Basin {basin_geo_name}. Skipping.\")\n",
    "        continue\n",
    "    if X_shap_cleaned.shape[0] < 2:\n",
    "        print(f\"  Too few samples ({X_shap_cleaned.shape[0]}) for SHAP analysis for Basin {basin_geo_name}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"  Shape of X_shap_cleaned (features for SHAP): {X_shap_cleaned.shape}\")\n",
    "    print(f\"  Cluster distribution: {np.bincount(y_clusters_cleaned)}\")\n",
    "\n",
    "    # Check clusters present in this basin\n",
    "    unique_clusters = np.unique(y_clusters_cleaned)\n",
    "    print(f\"  Clusters present in Basin {basin_geo_name}: {unique_clusters}\")\n",
    "\n",
    "    # --- Create SHAP Summary Plot for Each Cluster ---\n",
    "    for target_cluster in range(n_clusters_kmeans):  # Loop through all possible clusters (0 to 4)\n",
    "\n",
    "        # Check if this cluster exists in this basin\n",
    "        if target_cluster not in unique_clusters:\n",
    "            print(f\"    Cluster {target_cluster} not present in Basin {basin_geo_name}. Creating empty plot.\")\n",
    "\n",
    "            # Create empty plot for missing cluster\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.text(0.5, 0.5, f'Cluster {target_cluster}\\nNo models in this cluster\\nfor Basin {basin_geo_name}', \n",
    "                     ha='center', va='center', fontsize=16, transform=plt.gca().transAxes)\n",
    "            plt.xlim(0, 1)\n",
    "            plt.ylim(0, 1)\n",
    "            plt.axis('off')\n",
    "            plt.title(f'SHAP Summary Plot - Cluster {target_cluster}\\nExperiment: {shap_experiment_id}, Basin: {basin_geo_name}')\n",
    "\n",
    "            # Save empty plot\n",
    "            plot_filename = f'SHAP_Summary_Cluster_{target_cluster}_Exp_{shap_experiment_id}_Basin_{basin_geo_name}.png'\n",
    "            plt.savefig(os.path.join(exp_output_dir, plot_filename), dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            continue\n",
    "\n",
    "        # Count models in this cluster\n",
    "        cluster_count = np.sum(y_clusters_cleaned == target_cluster)\n",
    "        print(f\"    Processing Cluster {target_cluster} ({cluster_count} models)\")\n",
    "\n",
    "        # Create binary target: 1 if in this cluster, 0 otherwise\n",
    "        y_binary = (y_clusters_cleaned == target_cluster).astype(int)\n",
    "\n",
    "        # Check if we have enough samples and class balance\n",
    "        positive_samples = np.sum(y_binary)\n",
    "        negative_samples = len(y_binary) - positive_samples\n",
    "\n",
    "        print(f\"      Cluster {target_cluster}: {positive_samples} positive, {negative_samples} negative samples\")\n",
    "\n",
    "        # Skip if too few samples or perfect separation\n",
    "        if positive_samples < 2 or negative_samples < 2:\n",
    "            print(f\"      Insufficient samples for meaningful classification. Skipping Cluster {target_cluster}.\")\n",
    "\n",
    "            # Create diagnostic plot\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.text(0.5, 0.5, f'Cluster {target_cluster}\\nInsufficient samples for SHAP analysis\\n'\n",
    "                               f'{positive_samples} models in cluster, {negative_samples} models outside cluster\\n'\n",
    "                               f'Need at least 2 models in each group', \n",
    "                     ha='center', va='center', fontsize=14, transform=plt.gca().transAxes)\n",
    "            plt.xlim(0, 1)\n",
    "            plt.ylim(0, 1)\n",
    "            plt.axis('off')\n",
    "            plt.title(f'SHAP Summary Plot - Cluster {target_cluster}\\nExperiment: {shap_experiment_id}, Basin: {basin_geo_name}')\n",
    "\n",
    "            plot_filename = f'SHAP_Summary_Cluster_{target_cluster}_Exp_{shap_experiment_id}_Basin_{basin_geo_name}.png'\n",
    "            plt.savefig(os.path.join(exp_output_dir, plot_filename), dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            continue\n",
    "\n",
    "        # Train binary classifier for this cluster with adjusted parameters for small datasets\n",
    "        model = xgb.XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            n_estimators=50,  # Fewer trees for small datasets\n",
    "            random_state=42,\n",
    "            max_depth=2,      # Shallower trees to prevent overfitting\n",
    "            min_child_weight=1,  # Lower threshold for small datasets\n",
    "            learning_rate=0.3,   # Higher learning rate for faster convergence\n",
    "            subsample=1.0,       # Use all samples\n",
    "            colsample_bytree=1.0, # Use all features\n",
    "            reg_alpha=0.1,       # Add some regularization\n",
    "            reg_lambda=0.1,\n",
    "            scale_pos_weight=negative_samples / positive_samples if positive_samples > 0 else 1\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            model.fit(X_shap_cleaned, y_binary)\n",
    "            accuracy = model.score(X_shap_cleaned, y_binary)\n",
    "\n",
    "            # Get prediction probabilities to check if model is actually discriminating\n",
    "            y_pred_proba = model.predict_proba(X_shap_cleaned)[:, 1]\n",
    "            prob_range = np.max(y_pred_proba) - np.min(y_pred_proba)\n",
    "\n",
    "            print(f\"      Binary classifier accuracy for Cluster {target_cluster}: {accuracy:.2f}\")\n",
    "            print(f\"      Prediction probability range: {prob_range:.3f}\")\n",
    "\n",
    "            # If model isn't discriminating well, skip SHAP\n",
    "            if prob_range < 0.1:\n",
    "                print(f\"      Model predictions too uniform (range < 0.1). Skipping SHAP for Cluster {target_cluster}.\")\n",
    "\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                plt.text(0.5, 0.5, f'Cluster {target_cluster}\\nModel cannot distinguish cluster membership\\n'\n",
    "                                   f'Prediction probability range: {prob_range:.3f}\\n'\n",
    "                                   f'Features may not be informative for this cluster', \n",
    "                         ha='center', va='center', fontsize=14, transform=plt.gca().transAxes)\n",
    "                plt.xlim(0, 1)\n",
    "                plt.ylim(0, 1)\n",
    "                plt.axis('off')\n",
    "                plt.title(f'SHAP Summary Plot - Cluster {target_cluster}\\nExperiment: {shap_experiment_id}, Basin: {basin_geo_name}')\n",
    "\n",
    "                plot_filename = f'SHAP_Summary_Cluster_{target_cluster}_Exp_{shap_experiment_id}_Basin_{basin_geo_name}.png'\n",
    "                plt.savefig(os.path.join(exp_output_dir, plot_filename), dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                continue\n",
    "\n",
    "            # Calculate SHAP values\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            shap_values = explainer.shap_values(X_shap_cleaned)\n",
    "\n",
    "            # Check if SHAP values are meaningful\n",
    "            shap_range = np.max(np.abs(shap_values)) - np.min(np.abs(shap_values))\n",
    "            mean_abs_shap = np.mean(np.abs(shap_values))\n",
    "\n",
    "            print(f\"      SHAP value range: {shap_range:.4f}, Mean absolute SHAP: {mean_abs_shap:.4f}\")\n",
    "\n",
    "            if mean_abs_shap < 0.001:\n",
    "                print(f\"      SHAP values too small to be meaningful. Creating diagnostic plot.\")\n",
    "\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                plt.text(0.5, 0.5, f'Cluster {target_cluster}\\nSHAP values too small to interpret\\n'\n",
    "                                   f'Mean absolute SHAP value: {mean_abs_shap:.6f}\\n'\n",
    "                                   f'This suggests features don\\'t strongly distinguish this cluster', \n",
    "                         ha='center', va='center', fontsize=14, transform=plt.gca().transAxes)\n",
    "                plt.xlim(0, 1)\n",
    "                plt.ylim(0, 1)\n",
    "                plt.axis('off')\n",
    "                plt.title(f'SHAP Summary Plot - Cluster {target_cluster}\\nExperiment: {shap_experiment_id}, Basin: {basin_geo_name}')\n",
    "\n",
    "                plot_filename = f'SHAP_Summary_Cluster_{target_cluster}_Exp_{shap_experiment_id}_Basin_{basin_geo_name}.png'\n",
    "                plt.savefig(os.path.join(exp_output_dir, plot_filename), dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                continue\n",
    "\n",
    "            # Create SHAP Summary Plot\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            shap.summary_plot(shap_values, X_shap_cleaned, \n",
    "                              feature_names=X_shap_cleaned.columns, \n",
    "                              show=False, max_display=12)\n",
    "            plt.title(f'SHAP Summary Plot - Cluster {target_cluster}\\nExperiment: {shap_experiment_id}, Basin: {basin_geo_name}\\n'\n",
    "                      f'({cluster_count} models in cluster, Accuracy: {accuracy:.2f}, Mean |SHAP|: {mean_abs_shap:.4f})')\n",
    "            plt.tight_layout()\n",
    "\n",
    "            # Save the plot\n",
    "            plot_filename = f'SHAP_Summary_Cluster_{target_cluster}_Exp_{shap_experiment_id}_Basin_{basin_geo_name}.png'\n",
    "            plt.savefig(os.path.join(exp_output_dir, plot_filename), dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            print(f\"      SHAP Summary Plot saved: {plot_filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"      Error creating SHAP plot for Cluster {target_cluster}: {str(e)}\")\n",
    "\n",
    "            # Create error plot\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.text(0.5, 0.5, f'Cluster {target_cluster}\\nError in SHAP analysis\\n{str(e)[:100]}...', \n",
    "                     ha='center', va='center', fontsize=12, transform=plt.gca().transAxes)\n",
    "            plt.xlim(0, 1)\n",
    "            plt.ylim(0, 1)\n",
    "            plt.axis('off')\n",
    "            plt.title(f'SHAP Summary Plot - Cluster {target_cluster} (Error)\\nExperiment: {shap_experiment_id}, Basin: {basin_geo_name}')\n",
    "\n",
    "            plot_filename = f'SHAP_Summary_Cluster_{target_cluster}_Exp_{shap_experiment_id}_Basin_{basin_geo_name}.png'\n",
    "            plt.savefig(os.path.join(exp_output_dir, plot_filename), dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "    print(f\"\\n--- SHAP Analysis Complete for Basin {basin_geo_name} ---\")\n",
    "    print(f\"Created SHAP summary plots for all {n_clusters_kmeans} clusters\")\n",
    "\n",
    "    print(\"\\n--- All Basin SHAP Analysis Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d323e35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
